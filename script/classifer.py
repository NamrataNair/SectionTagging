# pre-requisites: put the embedding files in the working directory.
# do !pip install flair
# do !pip install allennlp
# prepare dataset by uncommenting the following block. 
#   dataset.csv is the file generated by topic-annotate tool.

'''
import pandas as pd
data = pd.read_csv("./dataset.csv").sample(frac=1, random_state=13).drop_duplicates()
data['label'] = '__label__' + data['label'].astype(str)
data.iloc[0:int(len(data)*0.8)].to_csv('train.csv', sep='\t', index = False, header = False)
data.iloc[int(len(data)*0.8):int(len(data)*0.9)].to_csv('test.csv', sep='\t', index = False, header = False)
data.iloc[int(len(data)*0.9):].to_csv('dev.csv', sep='\t', index = False, header = False);
'''

'''
# copy the cui2vec embedding locally and then execute the below
!gunzip cui2vec_embed_vectors.bin.gz
'''

'''
# copy the bert embedding directory locally
'''

from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings, BertEmbeddings, CharacterEmbeddings, ELMoEmbeddings

model_name = "glove"
runs = 1
use_glove = True
use_cui2vec = False
use_flair = False
use_elmo = False
use_bert = False 
mini_batch_size = 32
word_embeddings = []

if use_glove:
    word_embeddings.append(WordEmbeddings('glove'))
    word_embeddings.append(CharacterEmbeddings())
if use_cui2vec:
    word_embeddings.append(WordEmbeddings('./cui2vec_embed_vectors.bin'))
if use_flair:    
    word_embeddings.append(FlairEmbeddings('./forward-lm.pt'))
    word_embeddings.append(FlairEmbeddings('./backward-lm.pt'))
if use_elmo:    
    word_embeddings.append(ELMoEmbeddings('pubmed'))
if use_bert:
    word_embeddings.append(BertEmbeddings('./bert-base-clinical-cased'))
    mini_batch_size = 8
    
stacked_word_embeddings = StackedEmbeddings(word_embeddings)

from flair.embeddings import DocumentRNNEmbeddings

document_embeddings = DocumentRNNEmbeddings(word_embeddings, rnn_type='LSTM', bidirectional=True, hidden_size=512, reproject_words=True, reproject_words_dimension=256)

from flair.data_fetcher import NLPTaskDataFetcher
from flair.models import TextClassifier
from flair.trainers import ModelTrainer
from pathlib import Path
import time

corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')

classifier_embeddings = document_embeddings

for run in range(0,runs):
  #target_dir = srcdir + '/' + model_name + '/' + str(run)
  #!mkdir $target_dir

  classifier = TextClassifier(classifier_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)
  trainer = ModelTrainer(classifier, corpus)
  start_time = time.time()
  train_result = trainer.train('./', max_epochs=30, checkpoint=True, patience=3, mini_batch_size=mini_batch_size)
  end_time = time.time()
  
  with open('out.txt', "a") as f:
    f.write("Elapsed: " + str(end_time-start_time))
    f.write(str(train_result))

  #!cp ./*.pt $target_dir
  #!cp ./training.log $target_dir
  #!cp ./loss.tsv $target_dir
  #!cp ./out.txt $target_dir
  

# on the best experiment we can run predictions one last time and analyze the confusion matrix
def predict(model='./best-model.pt', test='./test.csv'):
  import pandas as pd
  from flair.models import TextClassifier
  from flair.data import Sentence
  classifier = TextClassifier.load(model)

  data_te = pd.read_csv(test, sep='\t', header=None, names=('label', 'text'), dtype={'label':'str', 'text':'str'})
  data_te.text = data_te.text.fillna(value="")
  sents = data_te['text'].tolist()
  tot = 0 
  mismatched = []
  y_true = []
  y_pred = []
  for i, sent in enumerate(sents):
    if (len(sent)==0): continue
    tot = tot + 1
    sentence = Sentence(sent)
    classifier.predict(sentence)
    row = data_te.iloc[i]
    y_true.append(row.label)
    y_pred.append("__label__"+sentence.labels[0].value)
    if "__label__"+sentence.labels[0].value!=row.label:
      mismatched.append({'sent': sent, 'true': row.label, 'pred': sentence.labels[0].value, 'score': sentence.labels[0].score})
  print ("Total: " + str(tot))  
  print ("Mismatched: " + str(len(mismatched)))

  from sklearn.metrics import classification_report
  print(classification_report(y_true, y_pred))

  df = pd.DataFrame(mismatched, columns=('sent', 'true', 'pred', 'score'))
  df.to_csv('mismatched.csv')

#predict()
